{
 "cells": [
  {
   "cell_type": "code",
   "id": "35af0992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:54:09.091774Z",
     "start_time": "2025-08-06T09:54:05.373091Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from cotracker.utils.visualizer import Visualizer, read_video_from_path\n",
    "from cotracker.models.core.model_utils import get_points_on_a_grid\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import map_coordinates\n",
    "import math\n",
    "\n",
    "#tried to clear memory because of OOM errors\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "DEFAULT_DEVICE = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "2bd32ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:55:22.830662Z",
     "start_time": "2025-08-06T09:55:22.825514Z"
    }
   },
   "source": [
    "def load_video(file, size=None):\n",
    "    \"\"\"\n",
    "    Load a video from the given file path, resize it to the specified size,\n",
    "    and return the video tensor and frames. \n",
    "    args:\n",
    "        file (str): Path to the video file.\n",
    "        size (tuple): Desired size for the video frames (width, height).\n",
    "    returns:\n",
    "        video (torch.Tensor): A tensor containing the video frames, resized to the specified size.\n",
    "        video_frames (list): A list of resized video frames as numpy arrays.\n",
    "    \"\"\"\n",
    "    video_path = file\n",
    "    video = read_video_from_path(video_path).squeeze()[:5,:,:]\n",
    "    print(f\"Video shape: {video.shape}\")\n",
    "    video_frames = np.expand_dims(np.array([frame for frame in video]),axis=-1)\n",
    "    print(f\"frames shape: {video_frames.shape}\")\n",
    "    video = torch.from_numpy(np.expand_dims(video, axis=0)).float()\n",
    "    print(f\"Video shape: {video.shape}\")\n",
    "    if size is not None:\n",
    "        video = torch.nn.functional.interpolate(video, size=size,\n",
    "                                           mode=\"bilinear\", align_corners=False)[None]\n",
    "\n",
    "    else:\n",
    "        video = np.expand_dims(video, axis=0)\n",
    "        print(f\"Video shape: {video.shape}\")\n",
    "        video = torch.from_numpy(video)\n",
    "    print(f\"Video shape: {video.shape}\")\n",
    "    video = video.permute(0,2,1,3,4).repeat(1,1,3,1,1).to(DEFAULT_DEVICE)#[:,:3,:,:,:]\n",
    "\n",
    "\n",
    "    print(f\"Video shape: {video.shape}\")\n",
    "    return video, video_frames"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "078475cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:55:22.985010Z",
     "start_time": "2025-08-06T09:55:22.980369Z"
    }
   },
   "source": [
    "def cotrack_model(video, grid_size):\n",
    "    \"\"\"\"Run the CoTracker model on the provided video and grid points.\n",
    "    Model defines which cotracker model is used for tracking.\n",
    "    args:\n",
    "        video (torch.Tensor): A tensor containing the video frames.\n",
    "        grid_size (int): The size of the grid for tracking.\n",
    "        points_x (list): List of x-coordinates for reference points.\n",
    "        points_y (list): List of y-coordinates for reference points.\n",
    "    returns:\n",
    "        pred_tracks (torch.Tensor): Predicted tracks from the model.\n",
    "        pred_visibility (torch.Tensor): Predicted visibility from the model.\n",
    "        grid_pts (torch.Tensor): Points on the grid used for tracking.\n",
    "    \"\"\"\n",
    "    model = (torch.hub.load(\"facebookresearch/co-tracker\", \"cotracker3_offline\").to\n",
    "             (\"cuda\"))\n",
    "    model = model.to(DEFAULT_DEVICE)\n",
    "    video = video.to(DEFAULT_DEVICE)\n",
    "    model.model.model_resolution = video.shape[3:]\n",
    "    grid_pts = get_points_on_a_grid(\n",
    "                grid_size, model.model.model_resolution\n",
    "            )\n",
    "\n",
    "    pred_tracks, pred_visibility = model(\n",
    "        video,\n",
    "        grid_size=grid_size,\n",
    "        grid_query_frame=0,\n",
    "        backward_tracking=True,\n",
    "    )\n",
    "    return pred_tracks, pred_visibility, grid_pts"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "5039bd8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:55:23.158062Z",
     "start_time": "2025-08-06T09:55:23.152746Z"
    }
   },
   "source": [
    "def warping(predicted_tracks, frames):      \n",
    "    \"\"\"\n",
    "    Warps the frames of a video based on predicted tracks.\n",
    "    args:       \n",
    "        predicted_tracks (torch.Tensor): Predicted tracks of shape (B, T, G, D).\n",
    "        frames (torch.Tensor): Video frames of shape (T_orig, H, W, C).\n",
    "    returns:\n",
    "        warpeds (list): List of warped frames.\n",
    "    \"\"\"\n",
    "    T_orig, H, W, C = frames.shape\n",
    "    B, T, G, D = predicted_tracks.shape\n",
    "    grid_size = int(math.sqrt(G))\n",
    "\n",
    "    velocity = predicted_tracks[0].reshape(T, grid_size, grid_size, 2) #(24, 32, 32, 2)\n",
    "    real_velocity = velocity-velocity[0] # (24, 32, 32, 2)\n",
    "    v = real_velocity.transpose(0, 3, 1, 2) # (24, 2, 32, 32)\n",
    "    vp = zoom(v, (1, 1, W/grid_size, H/grid_size))  #(24, 2, 256, 256)\n",
    "        \n",
    "    warpeds = [frames[0][...,0]]\n",
    "\n",
    "    for i in range(1,T_orig):\n",
    "        grid_x, grid_y = np.meshgrid(np.arange(W), np.arange(H))\n",
    "        grid_x = grid_x.astype(np.float32)\n",
    "        grid_y = grid_y.astype(np.float32)\n",
    "\n",
    "        phi = np.diff(vp,axis=0)[0:i].sum(0)\n",
    "        grid_x += phi[0].T\n",
    "        grid_y += phi[1].T\n",
    "  \n",
    "        warped = map_coordinates(frames[i][...,0].astype(np.float32), [grid_y, grid_x], order=3, mode='nearest')\n",
    "        warpeds.append(warped)\n",
    "       \n",
    "    return np.array(warpeds)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "7df2848e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:55:26.265786Z",
     "start_time": "2025-08-06T09:55:24.163794Z"
    }
   },
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "#define the video file path\n",
    "video_file = \"../../data/input/strong_movement/b5czi.tif\"\n",
    "if not os.path.exists(video_file):\n",
    "    print(f\"Video file {video_file} does not exist.\")\n",
    "else:\n",
    "    print(f\"Video file {video_file} exists.\")\n",
    "\n",
    "# Apply motion correction algorithm by\n",
    "# loading the video, running the CoTracker model, and warping the frames\n",
    "\n",
    "vid = load_video(video_file, size=None)\n",
    "pred_tracks = cotrack_model(vid[0], grid_size=16)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file ../../data/input/strong_movement/b5czi.tif exists.\n",
      "Video shape: (5, 258, 512)\n",
      "frames shape: (5, 258, 512, 1)\n",
      "Video shape: torch.Size([1, 5, 258, 512])\n",
      "Video shape: (1, 1, 5, 258, 512)\n",
      "Video shape: torch.Size([1, 1, 5, 258, 512])\n",
      "Video shape: torch.Size([1, 5, 3, 258, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\morit/.cache\\torch\\hub\\facebookresearch_co-tracker_main\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:55:32.111823Z",
     "start_time": "2025-08-06T09:55:29.852290Z"
    }
   },
   "cell_type": "code",
   "source": "result = warping(pred_tracks[0].cpu().numpy(), np.array(vid[1]))",
   "id": "5600cd776e23b734",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T17:26:13.553896Z",
     "start_time": "2025-08-04T17:26:13.548643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_and_display_video(array, filename='output.mp4', fps=30):\n",
    "    num_frames, height, width = array.shape\n",
    "\n",
    "    # Normalize and convert to uint8 if needed\n",
    "    if array.dtype != np.uint8:\n",
    "        array_min = array.min()\n",
    "        array_max = array.max()\n",
    "        array = 255 * (array - array_min) / (array_max - array_min + 1e-8)\n",
    "        array = np.clip(array, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # VideoWriter setup\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(filename, fourcc, fps, (width, height), isColor=True)\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        frame = array[i]\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)  # <- This line is critical\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video saved to {filename}\")"
   ],
   "id": "884f33862c9af7d3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T17:26:14.568366Z",
     "start_time": "2025-08-04T17:26:13.812951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_and_display_video(result, f'../../data/output/cotracker'\n",
    "                                             f'/cotracker_test.mp4')"
   ],
   "id": "803b8d47e1d9795f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/output/cotracker/cotracker_test.mp4\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "68b85cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T16:26:07.888547Z",
     "start_time": "2025-08-04T16:26:07.871152Z"
    }
   },
   "source": [
    "''# Print out warped results\n",
    "for i in range(result.shape[0]):\n",
    "    cv2.imwrite(f\"output/frame_{i:04d}.png\", result[i])  # Save each frame as an image\n",
    "print(\"Warped frames saved to output directory.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warped frames saved to output directory.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T16:26:07.972946Z",
     "start_time": "2025-08-04T16:26:07.964945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "nx, ny = (3, 2)\n",
    "\n",
    "x = np.linspace(0, 1, nx)\n",
    "print(x.shape)\n",
    "\n",
    "y = np.linspace(0, 1, ny)\n",
    "print(y.shape)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "xv.shape"
   ],
   "id": "f719c51f377d6d71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T16:26:08.063824Z",
     "start_time": "2025-08-04T16:26:08.060825Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "599e7cf3ef3b940",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracker-jn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
